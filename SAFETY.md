
# SAFETY — Safety‑Critical + OPSEC Guidance

## Not official guidance
This repository provides **educational prompt examples** only.
- Not official instruction, not training authorization, not mission approval.
- Does not create an instructor–student relationship.
- Does not supersede unit standards, AFIs/AFMANs, TOs, checklists, or training rules.

## Verification is mandatory
Always validate against authoritative sources appropriate to your platform and unit, including:
- Applicable AFIs/AFMANs, MAJCOM guidance, local supplements
- Platform TOs/checklists and approved publications
- Approved training rules and syllabi
- Stan/Eval standards and unit SOPs
- Approved weather, NOTAMs, airspace products, and ATC procedures

If anything conflicts, **authoritative sources govern**.

## LLM failure modes (common)
LLMs can:
- Hallucinate (“invent” procedures, numbers, or references)
- Be confidently wrong
- Miss context that changes risk materially
- Use outdated guidance
- Over-generalize and omit platform-specific constraints

## OPSEC / security guardrails
- Do **not** input classified, CUI, FOUO, sensitive mission details, frequencies, codes, tactics, or capabilities.
- Keep scenarios unclassified and generic.
- Prefer **local/offline** models for sensitive-but-unclassified workflows if allowed.

## Safe usage patterns
- Use LLMs for **structure**: briefs, debriefs, study outlines, and question drills.
- Keep procedural content **conceptual** unless you paste the exact authoritative reference text you’re working from.
- Ask the model to: (1) list assumptions, (2) flag uncertainty, (3) provide a “verify” checklist.
